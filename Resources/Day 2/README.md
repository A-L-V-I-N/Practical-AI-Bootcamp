# Building responsible AI - Bias and other issues
With great power comes great responsibility 
- Bias
- Accountability and explainability
- Reproducability
- Robustness
- Privacy

# Bias
AI and the datasets that power them were created by human begings with their own biases.
Some of the biases mentioned in google's machine learning glossary are :

## Selection bias
Selection bias is the bias introduced by the selection of individuals, groups, or data for analysis in such a way that proper randomization is not achieved.

## Implicit bias
Caused by assumptions. Also non as unconscious bias.

## Reporting bias
Poeple's tendancy to under-report all the information available

# Accountability and explainability

With machine learning we manually choose features. But that is not the case for deep learning. Here we don't know -
- How exactly the model works
- What patterns it learned
- Where it will work and where it will not

One thing we could is to allow reviews from customers and audits by experts

# Reproducability

We should be able to reproduce the past results of the model

- Document experimental conditions, dataset(s), benchmarks...etc
- Media sensationalising is a key problem
- Encourage companies to support publishing research papers
- Open source models and write about the development flow if possible

# Robustness

There are methods to change a single pixel in the image of mammooty to predict it as the image of mohanlal !

There are many other features that influence the predictions such as 
- noise
- lighting condtions
- camera angle

Inorder for users to trust AI we should make AI systems robust to withstand above mentioned issues.

# Privacy

Its not about data, its about information flow.

- Govts can push your company to get data for tracking people
- Personal data is toxic data. Keep less personal data
- Give transparency into what data is being collected
- Give option to delete data
- Minimise data we collect
- Use privacy preserved AI techniques 





